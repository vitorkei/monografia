
% RUSSEL, Stuart Jonathan and NORVIG, Peter - Artificial Intelligence: a mordern approach
% https://arxiv.org/pdf/1312.5602.pdf
% http://incompleteideas.net/book/bookdraft2017nov5.pdf
% https://books.google.com.br/books?id=sWV0DwAAQBAJ&printsec=frontcover&dq=reinforcement+learning+an+introduction+sutton+barto&hl=en&sa=X&ved=0ahUKEwiCyIzqj9feAhXChZAKHWuXAAQQ6AEIKjAA#v=onepage&q=reinforcement%20learning%20an%20introduction%20sutton%20barto&f=false

% RMSProp, slide 29: http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf

% asteroids com desempenho pior. Mesma arquitetura para diversos jogos diferentes. Conclui-se que Asteroids precisaria de uma arquitetura mais espec√≠fica
% https://arxiv.org/pdf/1509.06461.pdf
% https://www.cs.swarthmore.edu/~meeden/cs63/s15/nature15b.pdf
% https://arxiv.org/pdf/1511.06581.pdf
% https://arxiv.org/pdf/1511.05952.pdf
% https://arxiv.org/pdf/1710.02298.pdf
% https://arxiv.org/pdf/1703.03864.pdf

%@Book{russel2016artificial,
%  title={Artificial Intelligence: A Morden Approach},
%  author={Russel, S., and Norvig, P.},
%  isbn={9781292153964},
%  year={2016},
%  publisher={Pearson}
%}

@Book{sutton2018reinforcement,
  title={Reinforcement learning: an introduction},
  author={Sutton, Richard S., and Barto, Andrew G.},
  isbn={9780262039246},
  year={2018},
  publisher={MIT Press}
}

@Misc{
  rmsprop,
  author = {Geoffrey Hinton, Nitish Srivastava, Kevin Swersky},
  title = {Overview of mini-batch gradient descent},
  year = {2014},
  publisher = {Coursera},
  note = {https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf}
}

@article{DBLP:journals/corr/MnihKSGAWR13,
  author    = {Volodymyr Mnih and
               Koray Kavukcuoglu and
               David Silver and
               Alex Graves and
               Ioannis Antonoglou and
               Daan Wierstra and
               Martin A. Riedmiller},
  title     = {Playing Atari with Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1312.5602},
  year      = {2013},
  url       = {http://arxiv.org/abs/1312.5602},
  archivePrefix = {arXiv},
  eprint    = {1312.5602},
  timestamp = {Mon, 13 Aug 2018 16:47:42 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/MnihKSGAWR13},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{huber_loss,
  author = {Peter J. Huber},
  title = {Robust Estimation of a Location Parameter.},
  journal = {The Annals of Mathematical Statistics},
  volume = {35},
  year = {1964},
  url = {https://projecteuclid.org/euclid.aoms/1177703732}
}

@article{relu,
  author = {Richard H. R. Hahnloser and
            Rahul Sarpeshkar and
            Misha A. Mahowald and
            Rodney J. Douglas and
            H. Sebastian Seung},
  title = {Digital selection and analogue amplification coexist in a cortex-inspired silicon circuit},
  journal = {Nature},
  volume = {405},
  month = {06},
  year = {2000},
  publisher = {Macmillan Magazines Ltd.},
  biburl = {https://doi.org/10.1038/35016072}
}

@article{DBLP:journals/corr/HeZR015,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on
               ImageNet Classification},
  journal   = {CoRR},
  volume    = {abs/1502.01852},
  year      = {2015},
  url       = {http://arxiv.org/abs/1502.01852},
  archivePrefix = {arXiv},
  eprint    = {1502.01852},
  timestamp = {Mon, 13 Aug 2018 16:47:36 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HeZR015},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1207-4708,
  author    = {Marc G. Bellemare and
               Yavar Naddaf and
               Joel Veness and
               Michael Bowling},
  title     = {The Arcade Learning Environment: An Evaluation Platform for General
               Agents},
  journal   = {CoRR},
  volume    = {abs/1207.4708},
  year      = {2012},
  url       = {http://arxiv.org/abs/1207.4708},
  archivePrefix = {arXiv},
  eprint    = {1207.4708},
  timestamp = {Mon, 13 Aug 2018 16:46:44 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1207-4708},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Article{Lin1992,
  author="Lin, Long-Ji",
  title="Self-improving reactive agents based on reinforcement learning, planning and teaching",
  journal="Machine Learning",
  year="1992",
  month="May",
  day="01",
  volume="8",
  number="3",
  pages="293--321",
  abstract="To date, reinforcement learning has mostly been studied solving simple learning tasks. Reinforcement learning methods that have been studied so far typically converge slowly. The purpose of this work is thus two-fold: 1) to investigate the utility of reinforcement learning in solving much more complicated learning tasks than previously studied, and 2) to investigate methods that will speed up reinforcement learning.",
  issn="1573-0565",
  doi="10.1007/BF00992699",
  url="https://doi.org/10.1007/BF00992699"
}

@InProceedings{pmlr-v9-glorot10a,
  title = 	 {Understanding the difficulty of training deep feedforward neural networks},
  author = 	 {Xavier Glorot and Yoshua Bengio},
  booktitle = 	 {Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {249--256},
  year = 	 {2010},
  editor = 	 {Yee Whye Teh and Mike Titterington},
  volume = 	 {9},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Chia Laguna Resort, Sardinia, Italy},
  month = 	 {13--15 May},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf},
  url = 	 {http://proceedings.mlr.press/v9/glorot10a.html},
  abstract = 	 {Whereas before 2006 it appears that deep multi-layer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future.  We first observe the influence of the non-linear activations functions. We find that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we find that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We find that a new non-linearity that saturates less can often be beneficial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difficult when the singular values of the Jacobian associated with each layer are far from 1.  Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence.}
}

@article{DBLP:journals/corr/HasseltGS15,
  author    = {Hado van Hasselt and
               Arthur Guez and
               David Silver},
  title     = {Deep Reinforcement Learning with Double Q-learning},
  journal   = {CoRR},
  volume    = {abs/1509.06461},
  year      = {2015},
  url       = {http://arxiv.org/abs/1509.06461},
  archivePrefix = {arXiv},
  eprint    = {1509.06461},
  timestamp = {Mon, 13 Aug 2018 16:47:32 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HasseltGS15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/WangFL15,
  author    = {Ziyu Wang and
               Nando de Freitas and
               Marc Lanctot},
  title     = {Dueling Network Architectures for Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1511.06581},
  year      = {2015},
  url       = {http://arxiv.org/abs/1511.06581},
  archivePrefix = {arXiv},
  eprint    = {1511.06581},
  timestamp = {Mon, 13 Aug 2018 16:48:17 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/WangFL15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1710-02298,
  author    = {Matteo Hessel and
               Joseph Modayil and
               Hado van Hasselt and
               Tom Schaul and
               Georg Ostrovski and
               Will Dabney and
               Daniel Horgan and
               Bilal Piot and
               Mohammad Gheshlaghi Azar and
               David Silver},
  title     = {Rainbow: Combining Improvements in Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1710.02298},
  year      = {2017},
  url       = {http://arxiv.org/abs/1710.02298},
  archivePrefix = {arXiv},
  eprint    = {1710.02298},
  timestamp = {Mon, 13 Aug 2018 16:48:05 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1710-02298},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@Misc{
  stella,
  author = {Bradford W. Mott, Stephen Anthony, The Stella Team},
  title = {Stella: "A Multi-Platform Atari 2600 VCS Emulator"},
  year = {1995},
  url = "https://stella-emu.github.io/",
  note = {[Online; last accessed January 5th, 2019]}
}
